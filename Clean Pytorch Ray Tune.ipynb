{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebf8167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import ray\n",
    "from ray import tune, air\n",
    "\n",
    "import sys\n",
    "sys.path.append('./data')\n",
    "sys.path.append('./training')\n",
    "import data, training\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b35134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE=96\n",
    "WINDOW_SIZE=32\n",
    "NUM_WORKERS=6\n",
    "N_FEATURES=1\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N_TRIES=8 # Increase to try a larger search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e855c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 18:24:58,836\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.6</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.10.6', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '10.0.0.153', 'raylet_ip_address': '10.0.0.153', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-04-12_18-24-56_411700_4362/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-04-12_18-24-56_411700_4362/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2023-04-12_18-24-56_411700_4362', 'metrics_export_port': 54185, 'gcs_address': '10.0.0.153:58701', 'address': '10.0.0.153:58701', 'dashboard_agent_listen_port': 52365, 'node_id': '99fd1c8f441e7ac036561fd3778386e29c3d23b673b3746ead7bd3ee'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=int(os.cpu_count() * .75), num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3392a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to go requests route to avoid forbidden error\n",
    "url = 'https://stockanalysis.com/list/biggest-companies/'\n",
    "\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "dfs = pd.read_html(r.text)\n",
    "\n",
    "symbols = list(dfs[0]['Symbol'].iloc[:25].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbc5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  25 of 25 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No timezone found, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of days for YFinance 5m data is 60, but it only takes 59 day diff\n",
    "end_date = datetime.date.today() \n",
    "start_date = end_date - datetime.timedelta(days=59)\n",
    "\n",
    "dataset = yf.download(\n",
    "    symbols,\n",
    "    period='max', \n",
    "    interval='5m',\n",
    "    start=start_date, \n",
    "    end=end_date\n",
    ")['Adj Close']\n",
    "\n",
    "train, val = data.get_train_val_dicts(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9967f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'device': DEVICE,\n",
    "    'D_MODEL': tune.choice([32, 64]),\n",
    "    'N_HEADS': tune.choice([2, 8]),\n",
    "    'D_FF': tune.choice([128, 256]),\n",
    "    'DROPOUT': tune.choice([0., .05, .1, .15]),\n",
    "    'ACTIVATION': tune.choice(['relu', 'gelu']),\n",
    "    'NUM_LAYERS': tune.choice([3, 5]),\n",
    "    'LR': tune.choice([1e-3, 1e-4, 1e-5]),\n",
    "    'WINDOW_SIZE': tune.choice([32, 64])\n",
    "}\n",
    "param_space = {'train_loop_config': config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3df8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 18:25:02,527\tWARNING bohb_search.py:152 -- You passed a `space` parameter to <class 'ray.tune.search.bohb.bohb_search.TuneBOHB'> that contained unresolved search space definitions. <class 'ray.tune.search.bohb.bohb_search.TuneBOHB'> should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `param_space` argument to `tune.Tuner()` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2023-04-12 18:27:17 (running for 00:02:14.93)<br>Memory usage on this node: 5.3/62.4 GiB<br>Using HyperBand: num_stopped=0 total_brackets=2\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=80, Milestone (r)=3, completed=1.6%): {PAUSED: 6, PENDING: 1, RUNNING: 1} <br>Resources requested: 1.0/9 CPUs, 1.0/1 GPUs, 0.0/36.01 GiB heap, 0.0/18.01 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc            </th><th>train_loop_config...  </th><th style=\"text-align: right;\">  train_loop_config...</th><th style=\"text-align: right;\">  train_loop_config...</th><th style=\"text-align: right;\">  train_loop_config...</th><th style=\"text-align: right;\">  train_loop_config/LR</th><th style=\"text-align: right;\">  train_loop_config...</th><th style=\"text-align: right;\">  train_loop_config...</th><th style=\"text-align: right;\">  train_loop_config...</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  _timestamp</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_1e8c9764</td><td>RUNNING </td><td>10.0.0.153:6288</td><td>gelu                  </td><td style=\"text-align: right;\">                  0   </td><td style=\"text-align: right;\">                   256</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">                0.0001</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">            </td></tr>\n",
       "<tr><td>TorchTrainer_de38ff04</td><td>PAUSED  </td><td>10.0.0.153:4922</td><td>gelu                  </td><td style=\"text-align: right;\">                  0.05</td><td style=\"text-align: right;\">                   128</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">                0.001 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         17.147 </td><td style=\"text-align: right;\">    137.254 </td><td style=\"text-align: right;\">  133.518 </td><td style=\"text-align: right;\">  1681338323</td></tr>\n",
       "<tr><td>TorchTrainer_e08cee14</td><td>PAUSED  </td><td>10.0.0.153:5085</td><td>relu                  </td><td style=\"text-align: right;\">                  0   </td><td style=\"text-align: right;\">                   256</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">                1e-05 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         15.6769</td><td style=\"text-align: right;\">    136.741 </td><td style=\"text-align: right;\">  133.34  </td><td style=\"text-align: right;\">  1681338343</td></tr>\n",
       "<tr><td>TorchTrainer_eb48e66e</td><td>PAUSED  </td><td>10.0.0.153:5258</td><td>gelu                  </td><td style=\"text-align: right;\">                  0   </td><td style=\"text-align: right;\">                   256</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">                0.0001</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         17.972 </td><td style=\"text-align: right;\">     55.4542</td><td style=\"text-align: right;\">   53.7218</td><td style=\"text-align: right;\">  1681338365</td></tr>\n",
       "<tr><td>TorchTrainer_f735046c</td><td>PAUSED  </td><td>10.0.0.153:5709</td><td>relu                  </td><td style=\"text-align: right;\">                  0.1 </td><td style=\"text-align: right;\">                   256</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">                0.0001</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         18.1625</td><td style=\"text-align: right;\">     56.1481</td><td style=\"text-align: right;\">   54.1533</td><td style=\"text-align: right;\">  1681338388</td></tr>\n",
       "<tr><td>TorchTrainer_0451cab8</td><td>PAUSED  </td><td>10.0.0.153:5900</td><td>gelu                  </td><td style=\"text-align: right;\">                  0.15</td><td style=\"text-align: right;\">                   128</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">                1e-05 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         17.6434</td><td style=\"text-align: right;\">     56.2803</td><td style=\"text-align: right;\">   54.3783</td><td style=\"text-align: right;\">  1681338409</td></tr>\n",
       "<tr><td>TorchTrainer_116ed93e</td><td>PAUSED  </td><td>10.0.0.153:6091</td><td>gelu                  </td><td style=\"text-align: right;\">                  0.05</td><td style=\"text-align: right;\">                   256</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">                0.0001</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         17.9782</td><td style=\"text-align: right;\">     56.2731</td><td style=\"text-align: right;\">   54.3535</td><td style=\"text-align: right;\">  1681338431</td></tr>\n",
       "<tr><td>TorchTrainer_2baa1e58</td><td>PENDING </td><td>               </td><td>relu                  </td><td style=\"text-align: right;\">                  0.05</td><td style=\"text-align: right;\">                   256</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">                0.001 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">            </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m 2023-04-12 18:25:09,151\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: wandb version 0.14.2 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: Tracking run with wandb version 0.13.4\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: Run data is saved locally in /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02/TorchTrainer_de38ff04_1_ACTIVATION=gelu,DROPOUT=0.0500,D_FF=128,D_MODEL=64,LR=0.0010,NUM_LAYERS=3,N_HEADS=2,WINDOW_SIZE=64_2023-04-12_18-25-02/rank_0/wandb/run-20230412_182511-1le3nxpz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: Syncing run hopeful-thunder-71\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/lavellea/torch_stock_transformer\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m wandb: 🚀 View run at https://wandb.ai/lavellea/torch_stock_transformer/runs/1le3nxpz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m 2023-04-12 18:25:19,594\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "  0%|          | 0/11 [00:00<?, ?it/s] \n",
      "  9%|▉         | 1/11 [00:00<00:09,  1.04it/s]\n",
      " 45%|████▌     | 5/11 [00:01<00:01,  5.90it/s]\n",
      " 82%|████████▏ | 9/11 [00:01<00:00, 10.64it/s]\n",
      "100%|██████████| 11/11 [00:01<00:00,  8.74it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_de38ff04:\n",
      "  _time_this_iter_s: 11.315113306045532\n",
      "  _timestamp: 1681338321\n",
      "  _training_iteration: 1\n",
      "  date: 2023-04-12_18-25-21\n",
      "  done: false\n",
      "  experiment_id: da2d6e69274644179338662861911a63\n",
      "  hostname: Ajax\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.153\n",
      "  pid: 4922\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 15.069329738616943\n",
      "  time_this_iter_s: 15.069329738616943\n",
      "  time_total_s: 15.069329738616943\n",
      "  timestamp: 1681338321\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 139.45068081942472\n",
      "  training_iteration: 1\n",
      "  trial_id: de38ff04\n",
      "  val_loss: 134.7938232421875\n",
      "  warmup_time: 0.0027675628662109375\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s] \n",
      " 27%|██▋       | 3/11 [00:00<00:00, 29.23it/s]\n",
      " 64%|██████▎   | 7/11 [00:00<00:00, 31.90it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 33.74it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "  0%|          | 0/11 [00:00<?, ?it/s] \n",
      " 36%|███▋      | 4/11 [00:00<00:00, 32.85it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34.43it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m Exception in thread MsgRouterThr:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 953, in run\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m     msg = self._read_message()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router_queue.py\", line 36, in _read_message\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m     msg = self._response_queue.get(timeout=1)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/queues.py\", line 117, in get\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m     res = self._recv_bytes()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 217, in recv_bytes\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=4961)\u001b[0m     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m 2023-04-12 18:25:30,483\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: Currently logged in as: lavellea. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: wandb version 0.14.2 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: Tracking run with wandb version 0.13.4\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: Run data is saved locally in /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02/TorchTrainer_e08cee14_2_ACTIVATION=relu,DROPOUT=0.0000,D_FF=256,D_MODEL=64,LR=0.0000,NUM_LAYERS=3,N_HEADS=2,WINDOW_SIZE=64_2023-04-12_18-25-24/rank_0/wandb/run-20230412_182532-1lrjdv2d\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: Syncing run zany-deluge-72\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/lavellea/torch_stock_transformer\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m wandb: 🚀 View run at https://wandb.ai/lavellea/torch_stock_transformer/runs/1lrjdv2d\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m 2023-04-12 18:25:40,008\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "  0%|          | 0/11 [00:00<?, ?it/s] \n",
      "  9%|▉         | 1/11 [00:00<00:05,  1.82it/s]\n",
      " 45%|████▌     | 5/11 [00:00<00:00,  9.12it/s]\n",
      " 82%|████████▏ | 9/11 [00:00<00:00, 14.87it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12.86it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_e08cee14:\n",
      "  _time_this_iter_s: 10.002774238586426\n",
      "  _timestamp: 1681338341\n",
      "  _training_iteration: 1\n",
      "  date: 2023-04-12_18-25-41\n",
      "  done: false\n",
      "  experiment_id: 7648a7046c42485d8e93a6f5e60e2d8b\n",
      "  hostname: Ajax\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.153\n",
      "  pid: 5085\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 13.537811279296875\n",
      "  time_this_iter_s: 13.537811279296875\n",
      "  time_total_s: 13.537811279296875\n",
      "  timestamp: 1681338341\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 138.860952203924\n",
      "  training_iteration: 1\n",
      "  trial_id: e08cee14\n",
      "  val_loss: 134.26481246948242\n",
      "  warmup_time: 0.002727031707763672\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s] \n",
      " 36%|███▋      | 4/11 [00:00<00:00, 33.06it/s]\n",
      " 73%|███████▎  | 8/11 [00:00<00:00, 33.21it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 33.64it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "  0%|          | 0/11 [00:00<?, ?it/s] \n",
      " 36%|███▋      | 4/11 [00:00<00:00, 32.56it/s]\n",
      " 73%|███████▎  | 8/11 [00:00<00:00, 33.03it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34.65it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m Exception in thread MsgRouterThr:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 953, in run\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     msg = self._read_message()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router_queue.py\", line 36, in _read_message\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     msg = self._response_queue.get(timeout=1)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/queues.py\", line 117, in get\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     res = self._recv_bytes()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 217, in recv_bytes\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     self._check_closed()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 141, in _check_closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m     raise OSError(\"handle is closed\")\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5132)\u001b[0m OSError: handle is closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m 2023-04-12 18:25:50,252\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: Currently logged in as: lavellea. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: wandb version 0.14.2 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: Tracking run with wandb version 0.13.4\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: Run data is saved locally in /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02/TorchTrainer_eb48e66e_3_ACTIVATION=gelu,DROPOUT=0.0000,D_FF=256,D_MODEL=64,LR=0.0001,NUM_LAYERS=5,N_HEADS=8,WINDOW_SIZE=32_2023-04-12_18-25-44/rank_0/wandb/run-20230412_182552-281v0c45\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: Syncing run playful-galaxy-73\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/lavellea/torch_stock_transformer\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m wandb: 🚀 View run at https://wandb.ai/lavellea/torch_stock_transformer/runs/281v0c45\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      "  5%|▍         | 1/21 [00:00<00:11,  1.68it/s]\n",
      " 19%|█▉        | 4/21 [00:00<00:02,  7.00it/s]\n",
      " 33%|███▎      | 7/21 [00:00<00:01, 11.58it/s]\n",
      " 48%|████▊     | 10/21 [00:00<00:00, 15.65it/s]\n",
      " 67%|██████▋   | 14/21 [00:01<00:00, 20.27it/s]\n",
      " 86%|████████▌ | 18/21 [00:01<00:00, 23.53it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 16.61it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_eb48e66e:\n",
      "  _time_this_iter_s: 10.716689586639404\n",
      "  _timestamp: 1681338361\n",
      "  _training_iteration: 1\n",
      "  date: 2023-04-12_18-26-02\n",
      "  done: false\n",
      "  experiment_id: 2ffa64fecfa9497c9a225f844def9245\n",
      "  hostname: Ajax\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.153\n",
      "  pid: 5258\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.233699560165405\n",
      "  time_this_iter_s: 14.233699560165405\n",
      "  time_total_s: 14.233699560165405\n",
      "  timestamp: 1681338362\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 56.292456853957404\n",
      "  training_iteration: 1\n",
      "  trial_id: eb48e66e\n",
      "  val_loss: 54.11529050554548\n",
      "  warmup_time: 0.0032842159271240234\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 34.27it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 33.49it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 32.54it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 32.61it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 32.58it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 34.34it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 33.05it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 32.22it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 32.20it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 32.90it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m Exception in thread MsgRouterThr:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 953, in run\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     msg = self._read_message()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router_queue.py\", line 36, in _read_message\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     msg = self._response_queue.get(timeout=1)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/queues.py\", line 117, in get\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     res = self._recv_bytes()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 217, in recv_bytes\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     self._check_closed()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 141, in _check_closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m     raise OSError(\"handle is closed\")\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5301)\u001b[0m OSError: handle is closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m 2023-04-12 18:26:12,617\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: Currently logged in as: lavellea. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: wandb version 0.14.2 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: Tracking run with wandb version 0.13.4\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: Run data is saved locally in /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02/TorchTrainer_f735046c_4_ACTIVATION=relu,DROPOUT=0.1000,D_FF=256,D_MODEL=32,LR=0.0001,NUM_LAYERS=5,N_HEADS=8,WINDOW_SIZE=32_2023-04-12_18-26-06/rank_0/wandb/run-20230412_182614-k5jat3bm\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: Syncing run distinctive-pine-74\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/lavellea/torch_stock_transformer\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m wandb: 🚀 View run at https://wandb.ai/lavellea/torch_stock_transformer/runs/k5jat3bm\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m 2023-04-12 18:26:21,965\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      "  5%|▍         | 1/21 [00:00<00:11,  1.71it/s]\n",
      " 24%|██▍       | 5/21 [00:00<00:01,  8.66it/s]\n",
      " 43%|████▎     | 9/21 [00:00<00:00, 14.42it/s]\n",
      " 62%|██████▏   | 13/21 [00:00<00:00, 18.82it/s]\n",
      " 81%|████████  | 17/21 [00:01<00:00, 22.39it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 17.26it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_f735046c:\n",
      "  _time_this_iter_s: 10.838027000427246\n",
      "  _timestamp: 1681338384\n",
      "  _training_iteration: 1\n",
      "  date: 2023-04-12_18-26-24\n",
      "  done: false\n",
      "  experiment_id: 260ae34e86064d70b9cb99c580ce75f9\n",
      "  hostname: Ajax\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.153\n",
      "  pid: 5709\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.430644989013672\n",
      "  time_this_iter_s: 14.430644989013672\n",
      "  time_total_s: 14.430644989013672\n",
      "  timestamp: 1681338384\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 56.862244560605006\n",
      "  training_iteration: 1\n",
      "  trial_id: f735046c\n",
      "  val_loss: 54.6884754725865\n",
      "  warmup_time: 0.002524137496948242\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 34.62it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 34.15it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 32.62it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 32.78it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 33.87it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 35.18it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 34.00it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 32.06it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 32.38it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 33.01it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m Exception in thread MsgRouterThr:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 953, in run\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     msg = self._read_message()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router_queue.py\", line 36, in _read_message\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     msg = self._response_queue.get(timeout=1)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/queues.py\", line 117, in get\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     res = self._recv_bytes()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 217, in recv_bytes\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     self._check_closed()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 141, in _check_closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m     raise OSError(\"handle is closed\")\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5753)\u001b[0m OSError: handle is closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m 2023-04-12 18:26:34,570\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: Currently logged in as: lavellea. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: wandb version 0.14.2 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: Tracking run with wandb version 0.13.4\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: Run data is saved locally in /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02/TorchTrainer_0451cab8_5_ACTIVATION=gelu,DROPOUT=0.1500,D_FF=128,D_MODEL=32,LR=0.0000,NUM_LAYERS=5,N_HEADS=2,WINDOW_SIZE=32_2023-04-12_18-26-28/rank_0/wandb/run-20230412_182636-2mdbkoul\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: Syncing run decent-rain-75\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/lavellea/torch_stock_transformer\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m wandb: 🚀 View run at https://wandb.ai/lavellea/torch_stock_transformer/runs/2mdbkoul\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m 2023-04-12 18:26:43,835\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      "  5%|▍         | 1/21 [00:00<00:10,  1.82it/s]\n",
      " 24%|██▍       | 5/21 [00:00<00:01,  9.49it/s]\n",
      " 43%|████▎     | 9/21 [00:00<00:00, 15.97it/s]\n",
      " 62%|██████▏   | 13/21 [00:00<00:00, 21.11it/s]\n",
      " 81%|████████  | 17/21 [00:00<00:00, 25.10it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 19.12it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_0451cab8:\n",
      "  _time_this_iter_s: 10.52669382095337\n",
      "  _timestamp: 1681338405\n",
      "  _training_iteration: 1\n",
      "  date: 2023-04-12_18-26-46\n",
      "  done: false\n",
      "  experiment_id: 9ecbf16fee1d4f1d9a3cbb2254514a0b\n",
      "  hostname: Ajax\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.153\n",
      "  pid: 5900\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.16873550415039\n",
      "  time_this_iter_s: 14.16873550415039\n",
      "  time_total_s: 14.16873550415039\n",
      "  timestamp: 1681338406\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 57.40310886928013\n",
      "  training_iteration: 1\n",
      "  trial_id: 0451cab8\n",
      "  val_loss: 54.84373528616769\n",
      "  warmup_time: 0.0027167797088623047\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 39.45it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 39.09it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 38.90it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 37.02it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 38.44it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 38.49it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 38.78it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 37.13it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 34.80it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 36.85it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m Exception in thread MsgRouterThr:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5949)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m 2023-04-12 18:26:56,490\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: Currently logged in as: lavellea. Use `wandb login --relogin` to force relogin\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: wandb version 0.14.2 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: Tracking run with wandb version 0.13.4\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: Run data is saved locally in /media/alexander/38F66E50F66E0E86/Users/Alexander/Downloads/Python Projects/medium_articles/bayesian_opt_hyperband/tfmr_logger/TorchTrainer_2023-04-12_18-25-02/TorchTrainer_116ed93e_6_ACTIVATION=gelu,DROPOUT=0.0500,D_FF=256,D_MODEL=32,LR=0.0001,NUM_LAYERS=5,N_HEADS=2,WINDOW_SIZE=32_2023-04-12_18-26-50/rank_0/wandb/run-20230412_182658-3at98y4z\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: Syncing run chocolate-sun-76\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/lavellea/torch_stock_transformer\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m wandb: 🚀 View run at https://wandb.ai/lavellea/torch_stock_transformer/runs/3at98y4z\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m 2023-04-12 18:27:05,843\tINFO train_loop_utils.py:300 -- Moving model to device: cuda:0\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      "  5%|▍         | 1/21 [00:00<00:11,  1.76it/s]\n",
      " 24%|██▍       | 5/21 [00:00<00:01,  9.05it/s]\n",
      " 43%|████▎     | 9/21 [00:00<00:00, 14.98it/s]\n",
      " 62%|██████▏   | 13/21 [00:00<00:00, 19.92it/s]\n",
      " 81%|████████  | 17/21 [00:01<00:00, 23.72it/s]\n",
      "100%|██████████| 21/21 [00:01<00:00, 18.04it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_116ed93e:\n",
      "  _time_this_iter_s: 10.730890989303589\n",
      "  _timestamp: 1681338428\n",
      "  _training_iteration: 1\n",
      "  date: 2023-04-12_18-27-08\n",
      "  done: false\n",
      "  experiment_id: 34d96ac2f649468482f48f8d0a42f5fc\n",
      "  hostname: Ajax\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.153\n",
      "  pid: 6091\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.395349264144897\n",
      "  time_this_iter_s: 14.395349264144897\n",
      "  time_total_s: 14.395349264144897\n",
      "  timestamp: 1681338428\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 57.08022617158436\n",
      "  training_iteration: 1\n",
      "  trial_id: 116ed93e\n",
      "  val_loss: 54.69199752807617\n",
      "  warmup_time: 0.0027391910552978516\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 35.62it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 35.66it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 35.80it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 36.58it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 36.80it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "  0%|          | 0/21 [00:00<?, ?it/s] \n",
      " 19%|█▉        | 4/21 [00:00<00:00, 33.22it/s]\n",
      " 38%|███▊      | 8/21 [00:00<00:00, 35.34it/s]\n",
      " 57%|█████▋    | 12/21 [00:00<00:00, 36.00it/s]\n",
      " 76%|███████▌  | 16/21 [00:00<00:00, 36.39it/s]\n",
      " 95%|█████████▌| 20/21 [00:00<00:00, 36.47it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 36.54it/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m /home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/torch/nn/modules/transformer.py:569: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   return torch._transformer_encoder_layer_fwd(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m Exception in thread MsgRouterThr:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/threading.py\", line 953, in run\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     self._target(*self._args, **self._kwargs)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     msg = self._read_message()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/site-packages/wandb/sdk/interface/router_queue.py\", line 36, in _read_message\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     msg = self._response_queue.get(timeout=1)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/queues.py\", line 117, in get\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     res = self._recv_bytes()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 217, in recv_bytes\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     self._check_closed()\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m   File \"/home/alexander/miniconda3/envs/hyperband/lib/python3.10/multiprocessing/connection.py\", line 141, in _check_closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m     raise OSError(\"handle is closed\")\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6138)\u001b[0m OSError: handle is closed\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6333)\u001b[0m 2023-04-12 18:27:18,519\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6333)\u001b[0m wandb: Currently logged in as: lavellea. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "trainer, tune_config = training.setup_ray(train, val, BATCH_SIZE, param_space, n_tries=N_TRIES)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainer,\n",
    "    run_config=air.RunConfig(\n",
    "        local_dir=\"./tfmr_logger/\",\n",
    "    ),\n",
    "    tune_config=tune_config,\n",
    ")\n",
    "\n",
    "result = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994d41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af91bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc03b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
